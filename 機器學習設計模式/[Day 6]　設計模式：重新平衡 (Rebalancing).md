# 摘要
　　資料不平衡即使反映了現實，仍可能導致模型偏向多數類別，因此今天的文章將處理非人為造成的資料不平衡。除了討論問題本身，我們今天也會進一步討論加權、平衡資料集等解決方法。
# 重新平衡
　　這種設計模式針對本質上就不平衡的資料集進行，處理的核心問題是：如何使用特定類別只有少數樣本的資料建構模型。
　　今天討論的「本質上的」不平衡是指**儘管資料集已經正確地反映了現實的狀況，但因為某個標籤佔完整資料集之極大比例**的緣故，而可能導致模型的訓練產生偏差。如果要處理的是回歸問題，不平衡的資料集指的是異常值遠高於或遠低於資料集中位數的資料，關於異常值的議題我們已經在 [[[Day 4]　建構 ML 系統的挑戰 — 資料品質]] 的「資料準確性」完成了討論。
　　以下介紹的方法無法處理因資料蒐集問題造成的不平衡，關於「不自然的」不平衡，相關解決方案請參考 [[[Day 5]　設計模式：公平的鏡頭 (Fairness Lens)]]。
## 問題
### 如果資料集的不平衡反映了現實，為什麼這還會是一個需要被處理的問題？
　　在 [[[Day 3]　建構 ML 系統的挑戰 — 多個目標]] ，我們在「延伸閱讀：不平衡的資料集」曾提到關於異常檢測的例子，因為異常在現實世界並不是常態，因此我們蒐集的所謂可反映現實情況的資料集注定存在嚴重不平衡的問題。那麼，既然這是正常的，我們為什麼必須對它進行處理呢？
　　主要原因是如果不處理這個問題，**模型的預測結果將偏向多數類別**。當「正常運作」的樣本數量遠超過「故障」樣本時，模型在訓練過程中會傾向於更頻繁地預測「正常運作」，因為這樣可以在整體上獲得較高的準確度。這將造成的問題是，如果機器有 99% 的機率正常運作，那即使模型把全部的預測資料都預測為「正常運作」也能達到高達 99% 的準確度。
　　如果少數類別的重要性並不高，或許這是一個可忽略的議題，然而，在處理這類不平衡的資料集時，少數樣本常常遠比多數樣本更加重要。
### 評估指標定義錯誤
　　同樣是在 [[[Day 3]　建構 ML 系統的挑戰 — 多個目標]] ，在「自訂評估指標 (Custom Evaluation Metrics)」，我們提到評估指標的問題。在異常偵測的例子中，在未處理資料不平衡的問題時，準確率就是錯誤的指標，更好的選擇應該是召回率，因為我們的重點是關注少數樣本被正確偵測的機率。
　　即使是平衡後的資料集，也需要注意在進行這類型的任務時，若成效不佳，是否是因為還合併了評估指標定義錯誤的問題。
## 解決方案
### 定義正確的評估指標
### 加權：指定每一個類別的重要性
　　直接指定每一個類別的重要性，並給予少數樣本更高的權重。這種權重是超參數的一種，是可以自己調整與測試的參數。在 Keras，`fit()` 這個 method 中有一個參數為 `class_weights`，這個參數的資料型別為字典，可用於指定每個類別的權重。
　　權重初始值可以先計算各類別在總樣本量中所佔比例的倒數，再將這些數值除以總類別數。在採用這種做法時，如果是二分類問題，少數類別僅佔所有資料集的 0.1%，最後得到的權重將約為多數類別的 1000 倍（實際計算值為 999）。
　　除了根據樣本量來分配權重外，還應該考慮實際應用情境作為參考。例如，若將 Worm 家族的惡意程式錯誤分類為良性所造成的影響比將 Trojan 家族錯誤分類為良性嚴重 5 倍，那麼就應該根據這些風險係數來調整權重分配，從而將專案的目標和實際需求反映到模型的設計中。
### 平衡資料集
　　需要格外注意的是，無論使用哪種方法來平衡資料集，**測試集必須維持未平衡、可反映現實狀態的比例**，驗證集的比例則視實際任務決定。
#### Downsample：減少多數類別的樣本量
　　做法是隨機刪除多數類別的樣本，以使資料平衡。這個方法常與 Ensemble 合併使用，步驟如下：
1. 對佔多數的類別進行 Downsample，然後採用全部少數類別的樣本。
2. 訓練一個模型，並把它加入群體 (ensemble)。
3. 重複
　　完成訓練之後，在預測的環節可以透過投票 (Vote) 來得到最終結果，相關演算法可以參考[這篇文章](https://tomohiroliu22.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98%E7%B3%BB%E5%88%97-29-%E9%9B%86%E6%88%90%E6%8A%95%E7%A5%A8%E5%88%86%E9%A1%9E-ensemble-voting-classifier-platt-scaling-cc3c1be8aa10)。透過多次訓練模型，並且在每次訓練過程中使用不同的隨機樣本，既能避免模型過度偏向多數類別，又能確保模型充分學習到多數類別樣本的細節，達到更完整的預測效果。
Oversampling：增加少數類別的樣本量
　　有一個可參考的做法是 SMOTE (Synthetic Minority Oversampling Technique)，這種做法最早被提出是在 [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/abs/1106.1813)，其他延伸方法還可以參考[這篇文章](https://medium.com/%E6%95%B8%E5%AD%B8-%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%88%87%E8%9F%92%E8%9B%87/smote-enn-%E8%A7%A3%E6%B1%BA%E6%95%B8%E6%93%9A%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%BB%BA%E6%A8%A1%E7%9A%84%E6%8E%A1%E6%A8%A3%E6%96%B9%E6%B3%95-cdb6324b711e)。
# 補充
## 多類別分類 vs. 多標籤分類
- 多類別分類：非二元分類問題，但每個樣本只會被分到一個類別，即僅擁有一個標籤，要處理的是一對一的任務。
- 多標籤分類：每個樣本可能被分類到一個以上的類別中，即可能擁有一個以上標籤，要處理的是一對多的任務（但可能同時包含一對一和一對多的情境）。
## 當模型的效能良好，混淆矩陣的對角線百分比和會接近 100% x 類別總數
　　原因是斜對角線的每一格皆代表該類別被預測正確的機率，因此若全部類別的預測正確率皆為 100%，對角線百分比和為將為100% x 類別總數。
　　本系列文之參考書中的範例圖並非完全以百分比的形式顯示混淆矩陣，這一點在深入閱讀這本書時可以特別留意。
## Precision vs. Recall
- Precion：被**預測**為陽性的樣本中，真的是陽性的比例。
- Recall：又稱為真陽率 (True Positive Rate, TPR) ，指的是**所有**陽性的樣本中，被預測為陽性的比例。
# 參考資料
- Machine Learning Design Patterns: Solutions to Common Challenges in Data Preparation, Model Building, and MLOps CH3 Design Pattern 10: Rebalancing
- [機器學習\統計方法: 模型評估-驗證指標(validation index)](https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%B5%B1%E8%A8%88%E6%96%B9%E6%B3%95-%E6%A8%A1%E5%9E%8B%E8%A9%95%E4%BC%B0-%E9%A9%97%E8%AD%89%E6%8C%87%E6%A8%99-b03825ff0814)
- [機器學習_學習筆記系列(29)：集成投票分類(Ensemble Voting Classifier)- Platt scaling](https://tomohiroliu22.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98%E7%B3%BB%E5%88%97-29-%E9%9B%86%E6%88%90%E6%8A%95%E7%A5%A8%E5%88%86%E9%A1%9E-ensemble-voting-classifier-platt-scaling-cc3c1be8aa10)
- [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/abs/1106.1813)
- [SMOTE + ENN : 解決數據不平衡建模的採樣方法](https://medium.com/%E6%95%B8%E5%AD%B8-%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%88%87%E8%9F%92%E8%9B%87/smote-enn-%E8%A7%A3%E6%B1%BA%E6%95%B8%E6%93%9A%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%BB%BA%E6%A8%A1%E7%9A%84%E6%8E%A1%E6%A8%A3%E6%96%B9%E6%B3%95-cdb6324b711e)