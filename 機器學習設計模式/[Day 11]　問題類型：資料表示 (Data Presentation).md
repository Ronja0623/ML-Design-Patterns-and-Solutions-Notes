# 摘要
　　今天將探討資料表示問題，也將進一步介紹「特徵工程」、「可學習資料表示法」等定義。此外，還簡要介紹了四種設計模式，並預告將於明後天深入討論 Hashed Feature 和 Embedding 設計模式。
# 資料表示
　　在 [[[Day 8]　建構 ML 系統的挑戰 — 資料漂移]] ，我們提過機器學習模型的核心本質是一個數學函數，而數學函數的輸入通常被定義為一個有限且特定的集合。因此，我們可以說，「**機器學習模型因其數學性質而只能對特定類型的資料作處理**」。
　　然而，現實世界中的資料形式往往更加多樣化，通常不會那麼剛好就能符合我們的需求，這也是為什麼我們需要討論資料表示問題。
## 特徵工程
　　如果我們將現實世界的輸入資料視為集合 `D`，我們擇定的機器學習模型的輸入必須於屬於集合 `X`，例如矩陣、向量空間、或布林變數。這個時候，我們可以說資料表示的核心問題是在於**如何找到一個合適的映射函數 `f: D -> X`，使每個資料點 `d ∈ D` 經 `f(d)` 後成為一個可被模型處理的向量或數值型資料**。
　　建立 X 來表示 D 的程序被稱為特徵工程，其中我們提到的特徵就是指「機器學習模型的輸入」，特徵工程是指「**將現實世界的輸入轉為特徵使其能夠表示輸入資料的程序**」。
## 可學習資料表示法
　　在 [[[Day 9]　設計模式：橋接資料格式 (Bridged Schema)]]，我們設定了一個用於銷售應用程式的訓練情境，然後我們提出了兩種解決方案：機率補值和靜態補值方法。在靜態補值方法的討論中，我們討論到對於分類變數，可以採用 one-hot 編碼的平均值來填補缺失資料，從而確保補值後的資料能夠與新模型的要求相匹配。
　　儘管我們說這樣的資料表示法是相對靜態的，但是它也不是一個靜態到直接被寫死的值，同樣地，在很多情境中，我們也會對資料表示方法存在類似的期待：我們希望這個值是經過某種演算法，或者甚至是同樣透過機器學習方法決定的，而非一個靜態的預設值。舉例來說，在決策樹或隨機森林中，特徵值的條件就是透過機器學習演算法決定的。儘管我們知道機器學習方法存在偏差，演算法存在缺陷，但大多時候我們終究必須承認它們計算出來的條件比我們手動設定的來得可信得多。
　　其中，透過機器學習方法決定的資料表示法，就被稱為**可學習資料表示法**。
## 設計模式簡介
　　這裡列出各個設計模式的特徵，書中討論了四種設計模式，我們只會在之後的文章中詳細介紹其中兩種。
- Embedding 設計模式
	- 目的：讓深度神經網路能自行學習資料表示法。
	- 可以被視為自動設計的特徵。
- Feature Cross 設計模式
	- 目的：當不只一個輸入變數時，用於簡化多值分類變數之間的 AND 關係。
- Hashed Feature 設計模式
	- 目的：使模型不需要知道特定輸入的所有潛在值。（分類標籤，但不知道完整的標籤列表）
- Multimodal Input 設計模式
	- 目的：表示不同類型的資料。（例如資料包含一張貓的圖和一首描述貓的詩）

　　其中我們將在 [[[Day 12]　設計模式：被雜湊的特徵 (Hashed Feature)]] 討論 Hashed Feature 設計模式，在 [[[Day 1]　邁向 MLOps 之旅]] 和 [[[Day 9]　設計模式：橋接資料格式 (Bridged Schema)]] 提過的 one-hot 編碼問題便將在這一篇文章中解決；接著我們會在 [[[Day 13]　設計模式：嵌入 (Embedding)]] 接續討論 Embedding 設計模式的部分。
# 參考資料
- Machine Learning Design Patterns: Solutions to Common Challenges in Data Preparation, Model Building, and MLOps CH2