# 摘要
　　今天我們探討了資料品質對機器學習模型的影響。為了避免「垃圾進，垃圾出」的問題，我們必須關注資料的準確性、完整性、一致性和即時性等方面。這篇文章討論了如何處理重複資料、錯誤標籤、缺失值等問題，並提供了常見的解決方法。
# 資料品質
## 資料準確性
### 重複的資料
- 解決方法：刪除重複的資料
### 錯誤的標籤或特徵
　　雖然更正資料是最理想的解決方案，但在實務上，除非出現大規模的錯誤，否則要找出個別錯誤非常困難。通常，我們可以在研究資料集時進行統計分析以識別異常值，常見的識別方法包括：
- 3倍標準差法 (Three standard deviation method)：假如資料呈現常態分布，那麼 95% 以上的資料會落在平均值正負三個標準差的範圍內，超過就可以視為異常值。
- 盒箱法 (Boxplots)：盒型圖是一種利用四分位數來檢測異常值的方法，在上四分位數 + 1.5 倍四分位距或下四分位數 - 1.5 倍四分位距之外的都可以視為異常值。
- 分群 (Clustering)：利用分群演算法（例如K-means、DBSCAN）將資料分成不同的群組，異常值可能會出現在非常小的群組中或者遠離其他群組。
  
　　常見的處理方法有：
- 直接刪除
- 視為缺失值
- 不處理
  
　　這裡的關鍵問題是：**該怎麼確定異常值就是錯誤的呢？** 想像一下，如果我們的資料是關於人體體溫的，而某個資料點顯示體溫為50°C，顯然就是不合理的。但是，假如某人的收入比其他人高出數倍，我們很難下結論說這就是錯誤的。此外，有時會發生離群值其實是重要特徵的狀況，例如信用卡盜刷偵測時，如果短時間有多筆大額交易、在異常的地點或時間進行交易，這樣的離群值正好是我們想要關注的，如果我們將它視為錯誤，那很可能反而會失去我們需要關注的重要資訊。
### 缺失值
　　因為缺失的資料可能也是一種潛在的特徵，例如收入較高的人可能為避免風險而選擇不填任職的公司，罹患特殊疾病的人可能出自於隱私考量而選擇留空，因此在處理缺失值之前需要先檢視缺失值缺失的原因。主要的原因可以分成以下三種：
- Missing not at random (MNAR)：資料的缺失是受到缺失欄位本身值的影響。
- Missing at random (MAR)：資料的缺失是受到其他欄位的值影響。
- Missing completely at random(MCAR)：資料的缺失是完全隨機的 -> 資料的缺失和所有資料的值都無關，是其他原因造成的。

　　常見的處理方法可以分成兩種：
- 刪除：視缺失資料的重要性與嚴重性決定
	- 刪除缺失欄位：缺失太多，難以處理
	- 刪除該筆資料：缺失次數不多，且該欄資料對模型預測又很重要
- 補值：先了解缺失原因，然後補進合理的值。
	- 統計數值：中位數、眾數、平均值
	- 近似資料補值：KNN 補值法
	- 向前補值：透過時間序列的相依性
	- 其他補值方法可以參考這篇文章：[如何處理缺失值(使用Python)](https://medium.com/jackys-blog/%E5%A6%82%E4%BD%95%E8%99%95%E7%90%86%E7%BC%BA%E5%A4%B1%E5%80%BC-%E4%BD%BF%E7%94%A8python-479e030a43c7)
## 資料完整性
### 模型認識的「世界」是否與欲應用的「真實世界」相同？
　　指的是訓練用的資料集是否包含所有將預測的資料類別。舉例來說，最早發現機器學習模型存在**偏見**時，這種偏見產生的原因之一就是訓練資料集中不同群體的代表性不足。例如，如果訓練資料集中主要包含白人男性的樣本，那麼模型在辨識女性與有色人種時的準確率就會較差，從而讓使用者對模型的結果感到失望。
　　
### 訓練資料是否包含每種標籤的不同呈現方式？
　　常見的例子是在影像辨識上。舉例來說，在 MNIST 手寫數字資料集中包含 0 ~ 9 的手寫數字，但是這個資料集主要來自歐美，如果應用到其他文化背景中，手寫數字的呈現方式就可能會有所不同，尤其是數字 1 和 7 ，這些數字在不同文化中有不同的書寫習慣。
![[Pasted image 20240918233829.png]]
## 資料一致性
　　資料被蒐集的標準、使用的標籤、特徵值被蒐集時採用的單位等是否一致也是影響模型表現的重要因素。例如，每個人對於痛覺的閾值不同，因此在對自己的痛覺評分時，標準也會因人而異。另一個例子是如果溫度資料來自不同組織，有些可能單位採用華氏，有些則採用絕對溫度。這種不一致性如果沒有在預處理階段加以處理，會導致模型訓練出現問題，進而影響預測的準確性。
　　由於今天討論到偏見的問題，因此剩餘常見的問題會到後天才接續討論，明天我們將先探討 Fairness Lens 的部分。
## 資料即時性
　　指的是從事件發生的瞬間到資料進入資料庫的時間差距，這在需要即時或近乎即時更新的機器學習系統中非常重要。舉例來說，對信用卡盜刷偵測來說，從信用卡刷出去的瞬間到進到模型準備預測的時間是多久？可容許的時間是多久？另一個例子是推薦系統，使用者的喜好多久更新一次？如果希望能捕捉到使用者剛好對馬桶感興趣的那瞬間，從使用者開始瀏覽相關內容到訓練模型的時間應該要有多快？
　　為了處理即時性的問題，一個可以參考的做法是追蹤事件發生的時間和資料被加入資料集的時間，其他方法還有：
### 資料流處理 (Stream Processing)
　　即時處理和分析資料，而不是先等待資料進入資料庫，常用的框架有 Apache Kafka, Apache Flink, Apache Spark Streaming。
### 邊緣運算 (Edge Computing)
　　在產生資料的邊緣設備先進行初步的處理和分析，而不是等待資料傳輸到伺服器才進行處理。例如信用卡盜刷偵測，就可以先在刷卡的點先進行初步的風險評估，然後才將結果和相關資料送到伺服器進一步分析。
　　其他關鍵字：分散式系統 (Distributed Systems), 聯邦學習 (Federated Learning)
### 增量學習 (Incremental Learning)
　　一種模型在新資料到達時逐步更新的方法，避免了重新訓練整個模型的過程，從而加速模型訓練和適應新資料的能力。
　　延伸關鍵字：機器學習遺忘 (Machine unlearning)：一種從模型中快速移除特定資料點的技術，而無需重訓練整個模型。
### 快取與暫存 (Caching and Buffering)
　　預先計算然後暫存，而不是在每次要使用時重訓練或重預測。
# 參考資料
- [AI相關公司愛考的面試題目(4) How do you detect if a new observation is outlier? What is a bias-variance trade off ?](https://kilong31442.medium.com/ai%E7%9B%B8%E9%97%9C%E5%85%AC%E5%8F%B8%E6%84%9B%E8%80%83%E7%9A%84%E9%9D%A2%E8%A9%A6%E9%A1%8C%E7%9B%AE-4-how-do-you-detect-if-a-new-observation-is-outlier-852be286cdb9)
- [資料科學常見觀念：缺失值處理](https://medium.com/@AppliedDataScienceWeeklyNew/%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8%E5%B8%B8%E8%A6%8B%E8%A7%80%E5%BF%B5-%E7%BC%BA%E5%A4%B1%E5%80%BC%E8%99%95%E7%90%86-8d62547d0c13)
- [德國人vs香港人手寫數目字](https://kyliecthapthong.medium.com/%E5%BE%B7%E5%9C%8B%E4%BA%BAvs%E9%A6%99%E6%B8%AF%E4%BA%BA%E6%89%8B%E5%AF%AB%E6%95%B8%E7%9B%AE%E5%AD%97-84c0fd9abc98)
- [Real-Time Stream Processing for Machine Learning and Data Mining](https://medium.com/@manasbhole2000/real-time-stream-processing-for-machine-learning-and-data-mining-cac760edd0b9)