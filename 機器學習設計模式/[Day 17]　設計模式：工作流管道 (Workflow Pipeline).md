# 摘要
　　今天介紹了機器學習工作流管道的概念，重點在於透過容器化和框架提升系統的可重複性與協作性。此外，文中介紹了常見的工具、歷程追蹤與 CI/CD 整合的方案，並強調開發和生產管道的差異以及協調系統的重要性。
# 工作流管道
　　藉由將整個機器學習流程容器化，或使用專門的框架，可以大幅提高結果的可重現性。隨著系統規模的擴大，機器學習專案的開發通常便不再適合由一個人自己開一個 notebook 來完成了，因此建立一個方便大家協作的模式或框架變得至關重要。
# 問題
　　在大學時期，剛開始與同學合作開發專案時，許多人可能都遇過這樣的情況：專案的整體邏輯沒有做好獨立封裝，而是緊密耦合在一起，結果某個同學修改了一部分，卻導致其他部分出錯，自己修正後，又影響到另一位組員負責的環節。
　　Workflow Pipeline 的目標就是將每個環節進行分割，或稱為解耦，讓系統開發過程中，只要大家對於開發有一定的共識，就能幾乎不相互影響。同時，它還能在進行系統整體測試時，幫助我們精確定位問題所在的子環節，進而提升系統的開發效率與可維護性。
　　總結來說，我們的目標是將自己負責的部分封裝成一個獨立的、容器化的服務，這有點像微服務的架構概念——微服務將大型系統拆分為小型、獨立的服務，每個服務專注於單一功能，並通過明確定義的接口進行通信。那麼，在機器學習系統的開發上，我們可以怎麼做呢？
## 解決方案
　　在這個解決方案中，工作可以分為兩個部分：分割和串接。
- 分割：是將每個功能或模組封裝進容器，並透過 REST API 對外提供服務，使每個模組都能成為獨立、可重複使用的單元。
- 串接：將這些 API 串聯起來，組成一個完整的工作流程 (Pipeline) 。
### 這麼做的好處有哪些？
1. 讓大家可以各自獨立作業
2. 使機器學習的訓練過程可重現，因為這樣能夠確保整體執行環境的一致性
3. 各別步驟可以用不同的執行環境和語言版本
4. 可以對每個步驟各別追蹤輸入、輸出、log
5. 可以選擇執行單一組件、部分組件、或完整的管道
### 建立管道的工具
#### 只能在雲端：
- Cloud AI Platform Pipelines
#### 兩個都可以（本地和雲端）：
- TensorFlow Extended (TFX)：可以在本地或雲端環境中使用，支持不同的部署選項。
- Kubeflow Pipelines (KFP)：可以部署在本地的 Kubernetes 集群或雲端上（如 Google Cloud、AWS 等）。
- MLflow：主要在本地部署，也能夠在雲端使用，可以集成多種雲服務平台。
- Apache Airflow：可以在本地運行，也能通過雲服務提供商（如 AWS、Google Cloud 等）進行雲端部署。
### 各個階段能用的工具：以 TFX 為例
　　以下整理常見的組件，也可以嘗試自訂組件。
#### 資料收集
- ExampleGen：用於從外部接收資料，可以將 CSV, TFRecords, BigQuery 或其他自訂來源的資料引入管道中。
#### 資料驗證
- StatisticsGen：接收資料，並產生資料的統計摘要。
- SchemaGen：用於輸出從資料推理出的資料格式 (schema)。
- ExampleValidator：用於對資料集進行異常檢測，檢查的主要是資料漂移或潛在的訓練／伺服傾斜 (Training-Serving Skew) 的跡象。關於資料的異常檢測我們曾在 [[[Day 4]　建構 ML 系統的挑戰 — 資料品質]] 做過討論，資料漂移在 [[[Day 8]　建構 ML 系統的挑戰 — 資料漂移]]，關於資料驗證的部分則是在 [[[Day 5]　設計模式：公平的鏡頭 (Fairness Lens)]]。
#### 資料預處理
- Transform：可以直接接收來自 SchemaGen 的輸出，並將資料轉換為正確的格式。此外，它還能處理與特徵工程相關的任務，例如我們 [[[Day 16]　設計模式：串接 (Cascade)]] 的 Workflow Pipeline 小節中提到的，將上游模型作為轉換方法來使用這個功能；同時，我們在 [[[Day 13]　設計模式：嵌入 (Embedding)]] 中提到的將資料轉換為 embedding 的方法也可以在這裡應用。
#### 訓練模型
- Trainer：可以指到一個定義模型程式碼的函式，並且指定訓練模型的位置，要和 Cloud AI Platform 串接的就是在這個環節。
#### 佈署模型
- Pusher：用於把模型佈署到 AI Platform 上。
　　不過其實通常還有其他步驟，例如共享模型、或者建立獨立的管道專用於 CI/CD 。
### 在雲端訓練模型：以 Cloud AI Platform Pipelines 為例
1. 將管道程式碼包成 Docker 容器，並放到 Google Cloud Registry（要放到能和訓練平台相配合的場域，而非直接放到 DockerHub）
2. 使用 TFX CLI 建立管道
　　利用 TFX 建立管道的好處是，不會被 Google Cloud 綁死，也可以串接使用 Azure 或 Amazon 等其他地方的服務。
### 歷程追蹤 (lineage tracking)
　　用於視覺化模型版本的歷史記錄，包括超參數、使用的資料集等後設資料，以及產物如資料集摘要、模型輸出和模型評估指標等。此外，它還可以追蹤並選擇模型的訓練和部署位置，以及儲存模型相關的參考資訊。最後，也能夠用於比較不同管道的運行結果，幫助開發者更直觀地分析模型性能，並進行版本管理。
## 其他方案
### 將管道和 CI/CD 整合
　　我們可以利用一些代管服務來設置觸發機制，這些觸發條件可以是排程，也可以採用無伺服器的事件驅動服務，當有資料加入時自動啟動管道。此外，我們還能自定義觸發條件，例如設置在有一定數量的資料進入後再啟動處理流程。
　　如果想基於程式碼的提交 (commit) 進行觸發，可以使用類似 Cloud Build 這樣的工具，並結合 GitHub Actions 或 GitHub Triggers 來實現自動化處理。
### 開發 vs. 生產管道
　　通常，我們在開發階段會使用 notebook 來進行原型設計。為了將這些原型轉換成可在生產環境中運行的腳本，我們可以借助一些工具，例如 Kale，來將 notebook 的工作流程自動化轉換為可部署的管道，從而實現從開發到生產的順利過渡。
### 協調 (orchestration)
　　協調指的是在管道中加入控制和邏輯，以決定哪些步驟應該被執行，以及根據步驟的結果來動態調整後續流程。通過協調，我們能夠更靈活地管理和控制工作流程，像是根據前一個步驟的輸出來決定是否繼續執行後續的步驟，或根據條件選擇不同的路徑來執行。
- 條件執行：根據特定條件或輸出的結果來決定某些步驟是否執行。
- 錯誤處理：在某些步驟失敗時，自動觸發補救措施或回滾操作。
- 步驟依賴管理：定義步驟之間的依賴關係，確保後續步驟只有在先前步驟成功後才執行。
- 並行執行：協調系統可以允許不同的步驟同時進行，提升整體效率。
# 補充
## GCS bucket
　　GCS Bucket (Google Cloud Storage Bucket) 是 Google Cloud 平台上的一種儲存服務，常被用於儲存大規模的資料集、模型產物、日誌文件、備份等。
# 參考資料
- Machine Learning Design Patterns: Solutions to Common Challenges in Data Preparation, Model Building, and MLOps CH6 Design Pattern: Workflow Pipeline